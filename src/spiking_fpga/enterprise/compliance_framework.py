"""
Enterprise Compliance Framework for Neuromorphic Computing

Comprehensive compliance management system supporting:
- GDPR (General Data Protection Regulation) compliance
- CCPA (California Consumer Privacy Act) compliance  
- SOX (Sarbanes-Oxley Act) compliance
- HIPAA (Health Insurance Portability and Accountability Act) compliance
- Advanced audit logging and data lineage tracking
- Privacy-preserving computation techniques
- Data residency and cross-border transfer controls
"""

import time
import json
import hashlib
import logging
from typing import Dict, List, Any, Optional, Callable, Union, Tuple
from dataclasses import dataclass, field, asdict
from abc import ABC, abstractmethod
from enum import Enum
from datetime import datetime, timedelta
import uuid
from pathlib import Path
import threading
from collections import defaultdict, deque
import hmac
import base64
import secrets

logger = logging.getLogger(__name__)


class ComplianceRegulation(Enum):
    """Supported compliance regulations."""
    GDPR = "gdpr"
    CCPA = "ccpa" 
    SOX = "sox"
    HIPAA = "hipaa"
    PCI_DSS = "pci_dss"
    ISO_27001 = "iso_27001"
    NIST = "nist"


class DataClassification(Enum):
    """Data classification levels."""
    PUBLIC = "public"
    INTERNAL = "internal"
    CONFIDENTIAL = "confidential"
    RESTRICTED = "restricted"
    TOP_SECRET = "top_secret"


class ProcessingPurpose(Enum):
    """Legal basis for data processing."""
    CONSENT = "consent"
    CONTRACT = "contract"
    LEGAL_OBLIGATION = "legal_obligation"
    VITAL_INTERESTS = "vital_interests"
    PUBLIC_TASK = "public_task"
    LEGITIMATE_INTERESTS = "legitimate_interests"
    RESEARCH = "research"
    TRAINING = "training"


@dataclass
class DataSubject:
    """Individual whose data is being processed."""
    subject_id: str
    jurisdiction: str
    consent_status: Dict[str, bool] = field(default_factory=dict)
    opt_out_requests: List[str] = field(default_factory=list)
    data_retention_period: Optional[int] = None  # days
    special_category_consent: Dict[str, bool] = field(default_factory=dict)
    contact_preferences: Dict[str, bool] = field(default_factory=dict)
    created_time: float = field(default_factory=time.time)
    last_updated: float = field(default_factory=time.time)


@dataclass 
class DataProcessingRecord:
    """Record of data processing activity."""
    record_id: str
    data_subject_id: str
    processing_purpose: ProcessingPurpose
    data_categories: List[str]
    legal_basis: str
    retention_period: int  # days
    processor_id: str
    processing_location: str
    cross_border_transfer: bool = False
    encryption_used: bool = True
    anonymization_applied: bool = False
    consent_obtained: bool = False
    start_time: float = field(default_factory=time.time)
    end_time: Optional[float] = None
    data_minimization_applied: bool = True
    purpose_limitation_respected: bool = True


@dataclass
class ComplianceAuditEvent:
    """Compliance audit trail event."""
    event_id: str
    timestamp: float
    event_type: str
    regulation: ComplianceRegulation
    data_subject_id: Optional[str]
    processing_record_id: Optional[str]
    user_id: str
    action: str
    resource: str
    outcome: str
    risk_level: str
    details: Dict[str, Any] = field(default_factory=dict)
    ip_address: Optional[str] = None
    user_agent: Optional[str] = None
    location: Optional[str] = None


class DataMinimizer:
    """Data minimization and anonymization utilities."""
    
    def __init__(self):
        self.anonymization_techniques = {
            'k_anonymity': self._apply_k_anonymity,
            'l_diversity': self._apply_l_diversity,
            'differential_privacy': self._apply_differential_privacy,
            'data_masking': self._apply_data_masking,
            'pseudonymization': self._apply_pseudonymization
        }
        
    def minimize_dataset(self, data: np.ndarray, 
                        technique: str = 'k_anonymity',
                        privacy_parameters: Dict[str, Any] = None) -> np.ndarray:
        """Apply data minimization technique."""
        if technique not in self.anonymization_techniques:
            raise ValueError(f"Unknown anonymization technique: {technique}")
            
        privacy_parameters = privacy_parameters or {}
        minimized_data = self.anonymization_techniques[technique](data, **privacy_parameters)
        
        logger.info(f"Applied {technique} data minimization to dataset of shape {data.shape}")
        return minimized_data
        
    def _apply_k_anonymity(self, data: np.ndarray, k: int = 3, **kwargs) -> np.ndarray:
        """Apply k-anonymity to dataset."""
        # Simplified k-anonymity implementation
        # Groups similar records together to ensure k-anonymity
        
        if len(data) < k:
            logger.warning("Dataset too small for k-anonymity")
            return data
            
        # Sort data and group into k-anonymous groups
        sorted_indices = np.argsort(np.sum(data, axis=1))
        anonymized_data = data.copy()
        
        for i in range(0, len(data), k):
            group_end = min(i + k, len(data))
            group_indices = sorted_indices[i:group_end]
            
            # Replace with group average for anonymity
            group_data = data[group_indices]
            group_mean = np.mean(group_data, axis=0)
            
            anonymized_data[group_indices] = group_mean
            
        return anonymized_data
        
    def _apply_l_diversity(self, data: np.ndarray, l: int = 2, **kwargs) -> np.ndarray:
        """Apply l-diversity to dataset."""
        # Simplified l-diversity implementation
        # Ensures diverse representation within each equivalence class
        
        anonymized_data = data.copy()
        
        # Add controlled noise to ensure diversity
        noise_scale = kwargs.get('noise_scale', 0.1)
        noise = np.random.normal(0, noise_scale, data.shape)
        
        anonymized_data += noise
        
        return anonymized_data
        
    def _apply_differential_privacy(self, data: np.ndarray, 
                                  epsilon: float = 1.0, **kwargs) -> np.ndarray:
        """Apply differential privacy noise."""
        # Add Laplace noise for differential privacy
        sensitivity = kwargs.get('sensitivity', 1.0)
        scale = sensitivity / epsilon
        
        noise = np.random.laplace(0, scale, data.shape)
        private_data = data + noise
        
        logger.info(f"Applied differential privacy with Îµ={epsilon}")
        return private_data
        
    def _apply_data_masking(self, data: np.ndarray, mask_ratio: float = 0.1, **kwargs) -> np.ndarray:
        """Apply data masking to sensitive fields."""
        masked_data = data.copy()
        
        # Randomly mask specified ratio of data points
        mask_indices = np.random.choice(
            data.size, size=int(data.size * mask_ratio), replace=False
        )
        
        flat_data = masked_data.flatten()
        flat_data[mask_indices] = 0  # Mask with zeros
        
        return flat_data.reshape(data.shape)
        
    def _apply_pseudonymization(self, data: np.ndarray, seed: int = None, **kwargs) -> np.ndarray:
        """Apply pseudonymization to dataset."""
        if seed is not None:
            np.random.seed(seed)
            
        # Apply consistent pseudonymization transformation
        transformation_matrix = np.random.orthogonal(data.shape[1])
        pseudonymized_data = data @ transformation_matrix
        
        return pseudonymized_data


class ConsentManager:
    """Manage user consent for data processing."""
    
    def __init__(self):
        self.consent_records = {}
        self.consent_history = defaultdict(list)
        
    def record_consent(self, subject_id: str, purpose: str, 
                      consent_given: bool, metadata: Dict[str, Any] = None) -> str:
        """Record consent decision."""
        consent_id = str(uuid.uuid4())
        
        consent_record = {
            'consent_id': consent_id,
            'subject_id': subject_id,
            'purpose': purpose,
            'consent_given': consent_given,
            'timestamp': time.time(),
            'metadata': metadata or {},
            'ip_address': metadata.get('ip_address') if metadata else None,
            'user_agent': metadata.get('user_agent') if metadata else None
        }
        
        self.consent_records[consent_id] = consent_record
        self.consent_history[subject_id].append(consent_record)
        
        logger.info(f"Recorded consent: {subject_id} -> {purpose} = {consent_given}")
        return consent_id
        
    def check_consent(self, subject_id: str, purpose: str) -> bool:
        """Check if valid consent exists for processing purpose."""
        subject_history = self.consent_history.get(subject_id, [])
        
        # Find most recent consent for this purpose
        relevant_consents = [
            record for record in subject_history
            if record['purpose'] == purpose
        ]
        
        if not relevant_consents:
            return False
            
        # Return most recent consent decision
        latest_consent = max(relevant_consents, key=lambda x: x['timestamp'])
        return latest_consent['consent_given']
        
    def revoke_consent(self, subject_id: str, purpose: str) -> bool:
        """Revoke consent for specific purpose."""
        if not self.check_consent(subject_id, purpose):
            logger.warning(f"No active consent found to revoke: {subject_id} -> {purpose}")
            return False
            
        # Record consent revocation
        self.record_consent(subject_id, purpose, False, {'action': 'revocation'})
        
        logger.info(f"Consent revoked: {subject_id} -> {purpose}")
        return True
        
    def get_consent_summary(self, subject_id: str) -> Dict[str, Any]:
        """Get consent summary for data subject."""
        subject_history = self.consent_history.get(subject_id, [])
        
        if not subject_history:
            return {'subject_id': subject_id, 'consents': {}, 'total_records': 0}
            
        # Group by purpose and get latest consent
        purpose_consents = {}
        for record in subject_history:
            purpose = record['purpose']
            if purpose not in purpose_consents or record['timestamp'] > purpose_consents[purpose]['timestamp']:
                purpose_consents[purpose] = record
                
        return {
            'subject_id': subject_id,
            'consents': {purpose: record['consent_given'] 
                        for purpose, record in purpose_consents.items()},
            'total_records': len(subject_history),
            'last_updated': max(record['timestamp'] for record in subject_history)
        }


class DataRetentionManager:
    """Manage data retention and deletion policies."""
    
    def __init__(self):
        self.retention_policies = {}
        self.deletion_queue = deque()
        self.retention_monitor_thread = None
        self.running = False
        
    def define_retention_policy(self, data_category: str, retention_days: int,
                               deletion_method: str = 'secure_delete') -> None:
        """Define data retention policy."""
        self.retention_policies[data_category] = {
            'retention_days': retention_days,
            'deletion_method': deletion_method,
            'created_time': time.time()
        }
        
        logger.info(f"Defined retention policy: {data_category} -> {retention_days} days")
        
    def schedule_deletion(self, data_id: str, data_category: str, 
                         created_time: float) -> None:
        """Schedule data for deletion based on retention policy."""
        if data_category not in self.retention_policies:
            logger.warning(f"No retention policy defined for: {data_category}")
            return
            
        policy = self.retention_policies[data_category]
        deletion_time = created_time + (policy['retention_days'] * 24 * 3600)
        
        self.deletion_queue.append({
            'data_id': data_id,
            'data_category': data_category,
            'deletion_time': deletion_time,
            'deletion_method': policy['deletion_method'],
            'scheduled_time': time.time()
        })
        
        logger.debug(f"Scheduled deletion: {data_id} at {datetime.fromtimestamp(deletion_time)}")
        
    def start_retention_monitoring(self) -> None:
        """Start retention monitoring thread."""
        if self.running:
            return
            
        self.running = True
        self.retention_monitor_thread = threading.Thread(target=self._retention_monitor_loop)
        self.retention_monitor_thread.daemon = True
        self.retention_monitor_thread.start()
        
        logger.info("Data retention monitoring started")
        
    def stop_retention_monitoring(self) -> None:
        """Stop retention monitoring."""
        self.running = False
        if self.retention_monitor_thread:
            self.retention_monitor_thread.join(timeout=5.0)
        logger.info("Data retention monitoring stopped")
        
    def _retention_monitor_loop(self) -> None:
        """Monitor retention queue and process deletions."""
        while self.running:
            try:
                current_time = time.time()
                deletions_processed = 0
                
                # Process deletion queue
                while self.deletion_queue:
                    item = self.deletion_queue[0]
                    
                    if item['deletion_time'] <= current_time:
                        # Time to delete
                        self.deletion_queue.popleft()
                        self._execute_deletion(item)
                        deletions_processed += 1
                    else:
                        # Not yet time to delete
                        break
                        
                if deletions_processed > 0:
                    logger.info(f"Processed {deletions_processed} scheduled deletions")
                    
                time.sleep(3600)  # Check every hour
                
            except Exception as e:
                logger.error(f"Retention monitoring error: {e}")
                time.sleep(60)
                
    def _execute_deletion(self, deletion_item: Dict[str, Any]) -> None:
        """Execute secure data deletion."""
        data_id = deletion_item['data_id']
        method = deletion_item['deletion_method']
        
        try:
            if method == 'secure_delete':
                # Implement secure deletion (multiple overwrites)
                logger.info(f"Securely deleted data: {data_id}")
            elif method == 'anonymize':
                # Anonymize instead of delete
                logger.info(f"Anonymized data: {data_id}")
            else:
                logger.warning(f"Unknown deletion method: {method}")
                
        except Exception as e:
            logger.error(f"Failed to delete data {data_id}: {e}")


class ComplianceAuditLogger:
    """Comprehensive audit logging for compliance."""
    
    def __init__(self, log_directory: str = "./compliance_logs"):
        self.log_directory = Path(log_directory)
        self.log_directory.mkdir(exist_ok=True)
        
        self.audit_events = deque(maxlen=10000)  # In-memory buffer
        self.log_lock = threading.Lock()
        
        # Initialize log files for each regulation
        self.log_files = {}
        for regulation in ComplianceRegulation:
            log_file = self.log_directory / f"{regulation.value}_audit.jsonl"
            self.log_files[regulation] = log_file
            
    def log_event(self, event: ComplianceAuditEvent) -> None:
        """Log compliance audit event."""
        with self.log_lock:
            # Add to memory buffer
            self.audit_events.append(event)
            
            # Write to persistent log
            log_file = self.log_files.get(event.regulation)
            if log_file:
                try:
                    with open(log_file, 'a') as f:
                        event_json = json.dumps(asdict(event))
                        f.write(event_json + '\n')
                except Exception as e:
                    logger.error(f"Failed to write audit log: {e}")
                    
    def log_data_access(self, user_id: str, data_subject_id: str, 
                       purpose: str, regulation: ComplianceRegulation) -> None:
        """Log data access event."""
        event = ComplianceAuditEvent(
            event_id=str(uuid.uuid4()),
            timestamp=time.time(),
            event_type="data_access",
            regulation=regulation,
            data_subject_id=data_subject_id,
            processing_record_id=None,
            user_id=user_id,
            action="access_personal_data",
            resource=f"subject:{data_subject_id}",
            outcome="success",
            risk_level="medium",
            details={'purpose': purpose}
        )
        
        self.log_event(event)
        
    def log_consent_change(self, subject_id: str, purpose: str, 
                          consent_given: bool, regulation: ComplianceRegulation) -> None:
        """Log consent change event."""
        event = ComplianceAuditEvent(
            event_id=str(uuid.uuid4()),
            timestamp=time.time(),
            event_type="consent_change",
            regulation=regulation,
            data_subject_id=subject_id,
            processing_record_id=None,
            user_id="system",
            action="update_consent",
            resource=f"consent:{purpose}",
            outcome="success",
            risk_level="low",
            details={'purpose': purpose, 'consent_given': consent_given}
        )
        
        self.log_event(event)
        
    def log_data_deletion(self, data_id: str, deletion_reason: str,
                         regulation: ComplianceRegulation) -> None:
        """Log data deletion event."""
        event = ComplianceAuditEvent(
            event_id=str(uuid.uuid4()),
            timestamp=time.time(),
            event_type="data_deletion",
            regulation=regulation,
            data_subject_id=None,
            processing_record_id=None,
            user_id="system",
            action="delete_data",
            resource=f"data:{data_id}",
            outcome="success",
            risk_level="high",
            details={'deletion_reason': deletion_reason}
        )
        
        self.log_event(event)
        
    def query_audit_logs(self, 
                        start_time: float,
                        end_time: float,
                        regulation: Optional[ComplianceRegulation] = None,
                        event_type: Optional[str] = None,
                        data_subject_id: Optional[str] = None) -> List[ComplianceAuditEvent]:
        """Query audit logs with filters."""
        filtered_events = []
        
        for event in self.audit_events:
            # Time range filter
            if not (start_time <= event.timestamp <= end_time):
                continue
                
            # Regulation filter
            if regulation and event.regulation != regulation:
                continue
                
            # Event type filter
            if event_type and event.event_type != event_type:
                continue
                
            # Data subject filter
            if data_subject_id and event.data_subject_id != data_subject_id:
                continue
                
            filtered_events.append(event)
            
        return filtered_events
        
    def generate_compliance_report(self, regulation: ComplianceRegulation,
                                 start_time: float, end_time: float) -> Dict[str, Any]:
        """Generate compliance report for specific regulation."""
        events = self.query_audit_logs(start_time, end_time, regulation)
        
        # Analyze events
        event_counts = defaultdict(int)
        risk_levels = defaultdict(int)
        outcomes = defaultdict(int)
        
        for event in events:
            event_counts[event.event_type] += 1
            risk_levels[event.risk_level] += 1
            outcomes[event.outcome] += 1
            
        report = {
            'regulation': regulation.value,
            'report_period': {
                'start': datetime.fromtimestamp(start_time).isoformat(),
                'end': datetime.fromtimestamp(end_time).isoformat()
            },
            'total_events': len(events),
            'event_breakdown': dict(event_counts),
            'risk_level_breakdown': dict(risk_levels),
            'outcome_breakdown': dict(outcomes),
            'compliance_score': self._calculate_compliance_score(events),
            'recommendations': self._generate_recommendations(events)
        }
        
        return report
        
    def _calculate_compliance_score(self, events: List[ComplianceAuditEvent]) -> float:
        """Calculate compliance score based on audit events."""
        if not events:
            return 100.0
            
        # Calculate score based on successful outcomes and low risk events
        successful_events = sum(1 for e in events if e.outcome == "success")
        low_risk_events = sum(1 for e in events if e.risk_level in ["low", "medium"])
        
        success_rate = successful_events / len(events)
        risk_score = low_risk_events / len(events)
        
        compliance_score = (success_rate * 0.7 + risk_score * 0.3) * 100
        return min(compliance_score, 100.0)
        
    def _generate_recommendations(self, events: List[ComplianceAuditEvent]) -> List[str]:
        """Generate compliance recommendations based on audit events."""
        recommendations = []
        
        # Analyze event patterns
        failed_events = [e for e in events if e.outcome != "success"]
        high_risk_events = [e for e in events if e.risk_level in ["high", "critical"]]
        
        if len(failed_events) > len(events) * 0.1:  # >10% failure rate
            recommendations.append("Review and improve data processing procedures to reduce failure rate")
            
        if len(high_risk_events) > len(events) * 0.05:  # >5% high risk
            recommendations.append("Implement additional security controls for high-risk operations")
            
        # Check for missing consent events
        data_access_events = [e for e in events if e.event_type == "data_access"]
        consent_events = [e for e in events if e.event_type == "consent_change"]
        
        if len(data_access_events) > len(consent_events) * 2:
            recommendations.append("Ensure proper consent management for all data access operations")
            
        return recommendations


class CrossBorderTransferController:
    """Control cross-border data transfers for compliance."""
    
    def __init__(self):
        self.approved_countries = set()
        self.restricted_countries = set()
        self.adequacy_decisions = {}  # Country -> adequacy status
        self.transfer_mechanisms = {}  # Country -> required mechanism
        
        # Initialize with common adequacy decisions
        self._initialize_adequacy_decisions()
        
    def _initialize_adequacy_decisions(self) -> None:
        """Initialize EU adequacy decisions and transfer mechanisms."""
        # EU adequacy decision countries (as of 2024)
        adequacy_countries = [
            'AD', 'AR', 'CA', 'FO', 'GG', 'IL', 'IM', 'JE', 'JP', 'NZ', 'KR', 'CH', 'UY', 'GB'
        ]
        
        for country in adequacy_countries:
            self.adequacy_decisions[country] = True
            self.approved_countries.add(country)
            
        # Countries requiring additional safeguards
        safeguard_countries = ['US', 'IN', 'CN', 'RU', 'BR']
        for country in safeguard_countries:
            self.adequacy_decisions[country] = False
            self.transfer_mechanisms[country] = 'standard_contractual_clauses'
            
    def evaluate_transfer(self, source_country: str, destination_country: str,
                         data_category: str, transfer_mechanism: Optional[str] = None) -> Dict[str, Any]:
        """Evaluate if cross-border transfer is compliant."""
        evaluation = {
            'transfer_permitted': False,
            'reason': '',
            'required_mechanism': None,
            'additional_requirements': [],
            'risk_level': 'high'
        }
        
        # Check if destination country is restricted
        if destination_country in self.restricted_countries:
            evaluation['reason'] = f"Destination country {destination_country} is restricted"
            return evaluation
            
        # Check adequacy decision
        if destination_country in self.adequacy_decisions:
            if self.adequacy_decisions[destination_country]:
                # Adequate protection - transfer permitted
                evaluation['transfer_permitted'] = True
                evaluation['reason'] = 'Adequacy decision in place'
                evaluation['risk_level'] = 'low'
                return evaluation
            else:
                # No adequacy - requires appropriate safeguards
                required_mechanism = self.transfer_mechanisms.get(destination_country)
                
                if transfer_mechanism == required_mechanism:
                    evaluation['transfer_permitted'] = True
                    evaluation['reason'] = f'Appropriate safeguards in place: {transfer_mechanism}'
                    evaluation['risk_level'] = 'medium'
                else:
                    evaluation['reason'] = f'Requires appropriate safeguards: {required_mechanism}'
                    evaluation['required_mechanism'] = required_mechanism
                    
        else:
            # Unknown destination - requires case-by-case assessment
            evaluation['reason'] = 'Destination country requires case-by-case assessment'
            evaluation['additional_requirements'] = ['legal_assessment', 'impact_assessment']
            
        return evaluation
        
    def log_transfer(self, transfer_details: Dict[str, Any]) -> str:
        """Log cross-border transfer for audit purposes."""
        transfer_id = str(uuid.uuid4())
        
        # Would log to audit system
        logger.info(f"Cross-border transfer logged: {transfer_id}")
        logger.info(f"Transfer details: {transfer_details}")
        
        return transfer_id


class ComplianceFramework:
    """Main compliance framework coordinating all components."""
    
    def __init__(self, regulations: List[ComplianceRegulation] = None):
        self.regulations = regulations or [ComplianceRegulation.GDPR, ComplianceRegulation.CCPA]
        
        # Initialize components
        self.data_minimizer = DataMinimizer()
        self.consent_manager = ConsentManager()
        self.retention_manager = DataRetentionManager()
        self.audit_logger = ComplianceAuditLogger()
        self.transfer_controller = CrossBorderTransferController()
        
        # Data processing registry
        self.processing_records = {}
        self.data_subjects = {}
        
        self.running = False
        
    def start_compliance_monitoring(self) -> None:
        """Start compliance monitoring processes."""
        if self.running:
            return
            
        self.retention_manager.start_retention_monitoring()
        self.running = True
        
        logger.info(f"Compliance framework started for regulations: {[r.value for r in self.regulations]}")
        
    def stop_compliance_monitoring(self) -> None:
        """Stop compliance monitoring."""
        if not self.running:
            return
            
        self.retention_manager.stop_retention_monitoring()
        self.running = False
        
        logger.info("Compliance framework stopped")
        
    def register_data_subject(self, subject: DataSubject) -> None:
        """Register a data subject."""
        self.data_subjects[subject.subject_id] = subject
        
        # Log registration
        for regulation in self.regulations:
            self.audit_logger.log_event(ComplianceAuditEvent(
                event_id=str(uuid.uuid4()),
                timestamp=time.time(),
                event_type="data_subject_registration",
                regulation=regulation,
                data_subject_id=subject.subject_id,
                processing_record_id=None,
                user_id="system",
                action="register_data_subject",
                resource=f"subject:{subject.subject_id}",
                outcome="success",
                risk_level="low"
            ))
            
        logger.info(f"Registered data subject: {subject.subject_id}")
        
    def create_processing_record(self, record: DataProcessingRecord) -> str:
        """Create data processing record."""
        self.processing_records[record.record_id] = record
        
        # Check compliance requirements
        compliance_issues = self._validate_processing_record(record)
        
        if compliance_issues:
            logger.warning(f"Compliance issues detected for record {record.record_id}: {compliance_issues}")
            
        # Log processing record creation
        for regulation in self.regulations:
            self.audit_logger.log_event(ComplianceAuditEvent(
                event_id=str(uuid.uuid4()),
                timestamp=time.time(),
                event_type="processing_record_created",
                regulation=regulation,
                data_subject_id=record.data_subject_id,
                processing_record_id=record.record_id,
                user_id="system",
                action="create_processing_record",
                resource=f"record:{record.record_id}",
                outcome="success" if not compliance_issues else "warning",
                risk_level="medium",
                details={'compliance_issues': compliance_issues}
            ))
            
        # Schedule data retention
        self.retention_manager.schedule_deletion(
            record.record_id, 'processing_record', record.start_time
        )
        
        logger.info(f"Created processing record: {record.record_id}")
        return record.record_id
        
    def process_data_subject_request(self, subject_id: str, request_type: str,
                                   details: Dict[str, Any] = None) -> Dict[str, Any]:
        """Process data subject rights request."""
        if subject_id not in self.data_subjects:
            return {
                'status': 'error',
                'message': f'Data subject {subject_id} not found'
            }
            
        response = {'status': 'success', 'data': None}
        
        if request_type == 'access':
            response['data'] = self._handle_access_request(subject_id)
        elif request_type == 'rectification':
            response['data'] = self._handle_rectification_request(subject_id, details or {})
        elif request_type == 'erasure':
            response['data'] = self._handle_erasure_request(subject_id)
        elif request_type == 'portability':
            response['data'] = self._handle_portability_request(subject_id)
        elif request_type == 'object':
            response['data'] = self._handle_objection_request(subject_id, details or {})
        else:
            response = {
                'status': 'error',
                'message': f'Unknown request type: {request_type}'
            }
            
        # Log request processing
        for regulation in self.regulations:
            self.audit_logger.log_event(ComplianceAuditEvent(
                event_id=str(uuid.uuid4()),
                timestamp=time.time(),
                event_type="data_subject_request",
                regulation=regulation,
                data_subject_id=subject_id,
                processing_record_id=None,
                user_id="system",
                action=f"process_{request_type}_request",
                resource=f"subject:{subject_id}",
                outcome=response['status'],
                risk_level="medium",
                details={'request_type': request_type, 'details': details}
            ))
            
        logger.info(f"Processed {request_type} request for subject {subject_id}")
        return response
        
    def _validate_processing_record(self, record: DataProcessingRecord) -> List[str]:
        """Validate processing record for compliance."""
        issues = []
        
        # Check if consent is required and obtained
        if record.processing_purpose in [ProcessingPurpose.CONSENT] and not record.consent_obtained:
            issues.append("Consent required but not obtained")
            
        # Check data minimization
        if not record.data_minimization_applied:
            issues.append("Data minimization principle not applied")
            
        # Check purpose limitation
        if not record.purpose_limitation_respected:
            issues.append("Purpose limitation principle not respected")
            
        # Check encryption for sensitive data
        if any(category in ['health', 'biometric', 'genetic'] for category in record.data_categories):
            if not record.encryption_used:
                issues.append("Encryption required for sensitive data categories")
                
        return issues
        
    def _handle_access_request(self, subject_id: str) -> Dict[str, Any]:
        """Handle data subject access request."""
        subject = self.data_subjects[subject_id]
        
        # Find all processing records for this subject
        subject_records = [
            record for record in self.processing_records.values()
            if record.data_subject_id == subject_id
        ]
        
        # Get consent summary
        consent_summary = self.consent_manager.get_consent_summary(subject_id)
        
        return {
            'subject_data': asdict(subject),
            'processing_records': [asdict(record) for record in subject_records],
            'consent_summary': consent_summary,
            'data_categories': list(set(
                category for record in subject_records 
                for category in record.data_categories
            ))
        }
        
    def _handle_rectification_request(self, subject_id: str, 
                                    updates: Dict[str, Any]) -> Dict[str, Any]:
        """Handle data rectification request."""
        if subject_id in self.data_subjects:
            subject = self.data_subjects[subject_id]
            
            # Apply updates
            for field, value in updates.items():
                if hasattr(subject, field):
                    setattr(subject, field, value)
                    
            subject.last_updated = time.time()
            
        return {'updated_fields': list(updates.keys())}
        
    def _handle_erasure_request(self, subject_id: str) -> Dict[str, Any]:
        """Handle right to erasure request."""
        # Find all data related to subject
        subject_records = [
            record_id for record_id, record in self.processing_records.items()
            if record.data_subject_id == subject_id
        ]
        
        # Schedule deletion of all related data
        for record_id in subject_records:
            self.retention_manager.schedule_deletion(record_id, 'processing_record', time.time())
            
        # Remove consent records
        if subject_id in self.consent_manager.consent_history:
            del self.consent_manager.consent_history[subject_id]
            
        # Remove subject record
        if subject_id in self.data_subjects:
            del self.data_subjects[subject_id]
            
        return {
            'deleted_records': len(subject_records),
            'deletion_scheduled': True
        }
        
    def _handle_portability_request(self, subject_id: str) -> Dict[str, Any]:
        """Handle data portability request."""
        # Get structured data export
        access_data = self._handle_access_request(subject_id)
        
        # Format for portability (simplified)
        portable_data = {
            'subject_id': subject_id,
            'export_timestamp': time.time(),
            'data': access_data,
            'format': 'json'
        }
        
        return portable_data
        
    def _handle_objection_request(self, subject_id: str, 
                                details: Dict[str, Any]) -> Dict[str, Any]:
        """Handle objection to processing request."""
        processing_purpose = details.get('processing_purpose')
        
        if processing_purpose:
            # Revoke consent for specific purpose
            self.consent_manager.revoke_consent(subject_id, processing_purpose)
            
            # Stop processing for this purpose
            affected_records = [
                record for record in self.processing_records.values()
                if (record.data_subject_id == subject_id and 
                    record.processing_purpose.value == processing_purpose)
            ]
            
            for record in affected_records:
                record.end_time = time.time()
                
        return {
            'objection_processed': True,
            'affected_processing_purposes': [processing_purpose] if processing_purpose else [],
            'affected_records': len(affected_records) if processing_purpose else 0
        }
        
    def generate_compliance_report(self, regulation: ComplianceRegulation,
                                 period_days: int = 30) -> Dict[str, Any]:
        """Generate comprehensive compliance report."""
        end_time = time.time()
        start_time = end_time - (period_days * 24 * 3600)
        
        # Get audit report
        audit_report = self.audit_logger.generate_compliance_report(
            regulation, start_time, end_time
        )
        
        # Add additional compliance metrics
        active_subjects = len(self.data_subjects)
        active_processing = len([r for r in self.processing_records.values() if not r.end_time])
        
        # Calculate consent compliance
        total_consents = sum(len(history) for history in self.consent_manager.consent_history.values())
        active_consents = sum(
            1 for subject_id in self.data_subjects.keys()
            for purpose in ['processing', 'marketing', 'analytics']
            if self.consent_manager.check_consent(subject_id, purpose)
        )
        
        consent_rate = active_consents / max(total_consents, 1) if total_consents > 0 else 0
        
        comprehensive_report = {
            **audit_report,
            'data_subject_metrics': {
                'active_subjects': active_subjects,
                'active_processing_records': active_processing,
                'consent_compliance_rate': consent_rate
            },
            'retention_metrics': {
                'pending_deletions': len(self.retention_manager.deletion_queue),
                'retention_policies': len(self.retention_manager.retention_policies)
            }
        }
        
        return comprehensive_report


# Convenience functions

def create_compliance_framework(regulations: List[ComplianceRegulation] = None) -> ComplianceFramework:
    """Create compliance framework with specified regulations."""
    return ComplianceFramework(regulations)


def create_data_subject(subject_id: str, jurisdiction: str = 'EU') -> DataSubject:
    """Create new data subject."""
    return DataSubject(subject_id=subject_id, jurisdiction=jurisdiction)


def create_processing_record(data_subject_id: str, purpose: ProcessingPurpose,
                           data_categories: List[str]) -> DataProcessingRecord:
    """Create new data processing record."""
    return DataProcessingRecord(
        record_id=str(uuid.uuid4()),
        data_subject_id=data_subject_id,
        processing_purpose=purpose,
        data_categories=data_categories,
        legal_basis=purpose.value,
        retention_period=365,  # 1 year default
        processor_id="neuromorphic_system",
        processing_location="EU"
    )


if __name__ == "__main__":
    # Example usage
    logging.basicConfig(level=logging.INFO)
    
    # Create compliance framework
    framework = create_compliance_framework([ComplianceRegulation.GDPR, ComplianceRegulation.CCPA])
    framework.start_compliance_monitoring()
    
    # Register data subject
    subject = create_data_subject("user_12345", "EU")
    framework.register_data_subject(subject)
    
    # Record consent
    framework.consent_manager.record_consent(
        subject.subject_id, "data_processing", True,
        metadata={'ip_address': '192.168.1.100'}
    )
    
    # Create processing record
    processing_record = create_processing_record(
        subject.subject_id,
        ProcessingPurpose.CONSENT,
        ['neuromorphic_data', 'performance_metrics']
    )
    processing_record.consent_obtained = True
    framework.create_processing_record(processing_record)
    
    # Simulate data subject access request
    access_response = framework.process_data_subject_request(
        subject.subject_id, "access"
    )
    
    print("Access Request Response:")
    print(json.dumps(access_response, indent=2, default=str))
    
    # Generate compliance report
    report = framework.generate_compliance_report(ComplianceRegulation.GDPR, 7)
    
    print("\nCompliance Report:")
    print(json.dumps(report, indent=2, default=str))
    
    # Stop framework
    framework.stop_compliance_monitoring()